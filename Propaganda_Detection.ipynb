{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMb0V2AuAJeqjhRHXtzCPMq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Takily/dbn-vs-cnn-image-classification/blob/main/Propaganda_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2fBXbG1Bo7m",
        "outputId": "c1b12875-a491-4860-f3b2-52b7d5a79149"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ka_1  ka_1.zip\t__MACOSX  sample_data\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"ka_1.zip\", \"r\") as z:\n",
        "    z.extractall(\".\")\n",
        "!ls\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv, os, re"
      ],
      "metadata": {
        "id": "OoQCHXvnSOHp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths in your Colab working directory\n",
        "ARTICLES_DIR = \"ka_1/test-articles-subtask-3\"\n",
        "LABELS_FILE  = \"ka_1/test-labels-subtask-3.txt\"\n",
        "OUTPUT_CSV   = \"ka_eval_paragraphs.csv\"\n",
        "INCLUDE_UNLABELED = False  # True if you also want paragraphs with no labels\n"
      ],
      "metadata": {
        "id": "6cVK5louSQKH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Read all article texts and split into paragraphs\n",
        "articles = {}\n",
        "for fname in sorted(os.listdir(ARTICLES_DIR)):\n",
        "    if fname.startswith(\"article\") and fname.endswith(\".txt\"):\n",
        "        article_id = re.findall(r\"\\d+\", fname)[0]\n",
        "        with open(os.path.join(ARTICLES_DIR, fname), \"r\", encoding=\"utf-8\") as f:\n",
        "            text = f.read()\n",
        "        paragraphs = [p.strip() for p in re.split(r\"\\n{1,}\", text) if p.strip()]\n",
        "        articles[article_id] = paragraphs\n",
        "print(f\"Loaded {len(articles)} articles\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyqz0QFzSfNa",
        "outputId": "7d1e2e3d-4460-46b6-9ca5-7d7a98b74c9d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 29 articles\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) Read paragraph-level labels\n",
        "labels_map = {}\n",
        "with open(LABELS_FILE, \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        line = line.strip()\n",
        "        if not line: continue\n",
        "        parts = line.split()\n",
        "        if len(parts) < 3: continue\n",
        "        art_id = parts[0]\n",
        "        para_idx = int(parts[1]) - 1  # 0-based\n",
        "        labels_str = \" \".join(parts[2:])\n",
        "        labs = [l.strip() for l in re.split(r\"[,\\s]+\", labels_str) if l.strip()]\n",
        "        labels_map[(art_id, para_idx)] = labs"
      ],
      "metadata": {
        "id": "UTykPtDpTK59"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rows = []\n",
        "for art_id, paras in articles.items():\n",
        "    for i, text in enumerate(paras):\n",
        "        key = (art_id, i)\n",
        "        labs = labels_map.get(key, [])\n",
        "        if labs or INCLUDE_UNLABELED:\n",
        "            rows.append({\n",
        "                \"article_id\": art_id,\n",
        "                \"para_id\": i + 1,\n",
        "                \"text\": text,\n",
        "                \"labels\": labs\n",
        "            })\n",
        "print(f\"Prepared {len(rows)} paragraph rows\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyVRPH5ATQff",
        "outputId": "ef951876-0283-4971-ea32-9719da93843f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prepared 38 paragraph rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4) Write CSV\n",
        "with open(OUTPUT_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "    writer = csv.DictWriter(f, fieldnames=[\"text\", \"labels\", \"article_id\", \"para_id\"])\n",
        "    writer.writeheader()\n",
        "    for r in rows:\n",
        "        writer.writerow({\n",
        "            \"text\": r[\"text\"],\n",
        "            \"labels\": \",\".join(r[\"labels\"]),\n",
        "            \"article_id\": r[\"article_id\"],\n",
        "            \"para_id\": r[\"para_id\"]\n",
        "        })\n",
        "print(f\"Saved to {OUTPUT_CSV}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0CGaIfsTTzO",
        "outputId": "eb7e490d-5700-41a2-ca85-57461c63c5d3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved to ka_eval_paragraphs.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python convert_paragraphs_to_csv.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVshhQckUx7S",
        "outputId": "3d069a00-d17d-4922-c2d3-68e870cdef71"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/convert_paragraphs_to_csv.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Install once (safe to re-run) ===\n",
        "!pip install -q transformers accelerate torch scikit-learn\n",
        "\n",
        "# === Imports ===\n",
        "import csv, json, re, sys\n",
        "import numpy as np\n",
        "from typing import List\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig\n",
        "import torch\n",
        "\n",
        "# === Config ===\n",
        "CSV_PATH   = \"ka_eval_paragraphs.csv\"             # your prepared eval CSV\n",
        "MODEL_NAME = \"ai-forever/mGPT\"                    # switch to \"ai-forever/mGPT-1.3B-georgian\" to use the Georgian-only model\n",
        "USE_FEW_SHOT = False                              # set True to enable the small FEW_SHOTS block\n",
        "\n",
        "# Few-shot seeds (tiny, editable). Keep short. Only used if USE_FEW_SHOT=True.\n",
        "FEW_SHOTS = [\n",
        "    {\"text\": \"ოპონენტები ხალხს ატყუებენ და საკუთარი ინტერესებისთვის იბრძვიან.\",\n",
        "     \"labels_en\": [\"Loaded_Language\",\"Name_Calling-Labeling\"]},\n",
        "    {\"text\": \"ჩვენი ტრადიციები საფრთხეშია, ამიტომ უნდა ვიდგეთ ერთ მუშტად.\",\n",
        "     \"labels_en\": [\"Flag_Waving\",\"Appeal_to_Fear-Prejudice\"]},\n",
        "]\n",
        "\n",
        "# Gold/eval label set (English — must match test set)\n",
        "ALLOWED_LABELS_EN = [\n",
        "    \"Doubt\", \"Guilt_by_Association\", \"Exaggeration-Minimisation\", \"Loaded_Language\",\n",
        "    \"Name_Calling-Labeling\", \"Questioning_the_Reputation\", \"Obfuscation-Vagueness-Confusion\",\n",
        "    \"Flag_Waving\", \"Red_Herring\", \"Appeal_to_Hypocrisy\", \"Consequential_Oversimplification\",\n",
        "    \"Causal_Oversimplification\", \"Repetition\", \"False_Dilemma-No_Choice\", \"Conversation_Killer\",\n",
        "    \"Appeal_to_Fear-Prejudice\", \"Appeal_to_Values\",\n",
        "    \"Appeal_to_Authority\",\"Straw_Man\"\n",
        "\n",
        "]\n",
        "\n",
        "# Georgian surface forms -> English mapping (expand if you want synonyms)\n",
        "GEO2EN = {\n",
        "    \"ეჭვის აღძვრა\": \"Doubt\",\n",
        "    \"დაბარელება ასოციაციით\": \"Guilt_by_Association\",\n",
        "    \"გაზვიადება - დაკნინება\": \"Exaggeration-Minimisation\",\n",
        "    \"პათეტიკური ენა\": \"Loaded_Language\",\n",
        "    \"სახელების დაძახება\": \"Name_Calling-Labeling\",\n",
        "    \"რეპუტაციის ეჭვქვეშ დაყენება\": \"Questioning_the_Reputation\",\n",
        "    \"ბუნდოვანება\": \"Obfuscation-Vagueness-Confusion\",\n",
        "    \"პოპულისტური პატრიოტიზმი\": \"Flag_Waving\",\n",
        "    \"ყურადღების გადატანა\": \"Red_Herring\",\n",
        "    \"თვალთმაქცობის დაბრალება\": \"Appeal_to_Hypocrisy\",\n",
        "    \"გამარტივებული მიზეზშედეგობრიობა\": \"Consequential_Oversimplification\",\n",
        "    \"მიზეზთა გამარტივება\": \"Causal_Oversimplification\",\n",
        "    \"განმეორებითი რიტორიკა\": \"Repetition\",\n",
        "    \"ცრუ დილემა - არჩევანის არარსებობა\": \"False_Dilemma-No_Choice\",\n",
        "    \"დისკუსიის დამხშობი\": \"Conversation_Killer\",\n",
        "    \"შიშით/წინასწარგანწყობით აპელირება\": \"Appeal_to_Fear-Prejudice\",\n",
        "    \"ღირებულებებით აპელირება\":\"Appeal_to_Values\",\n",
        "    \"ავტორიტეტით აპელირება\":\"Appeal_to_Authority\",\n",
        "    \"ცრუ კონტრარგუმენტი\":\"Straw_Man\"\n",
        " }\n",
        "\n",
        "# Bilingual label list for the prompt (EN with KA gloss so the model has semantics)\n",
        "BILINGUAL = [\n",
        "    \"Doubt (ეჭვის აღძვრა - სანდოობის შერყევა)\",\n",
        "    \"Guilt_by_Association (დაბარელება ასოციაციით - სახელშელახულ ჯგუფთან გაიგივება)\",\n",
        "    \"Exaggeration-Minimisation (გაზვიადება - დაკნინება - რეალობის გაბუქება ან შემცირება)\",\n",
        "    \"Loaded_Language (პათეტიკური ენა - ემოციურად დატვირთული ენა)\",\n",
        "    \"Name_Calling-Labeling (სახელების დაძახება - პოზიტიური ან ნეგატიური იარლიყით მანიპულაცია)\",\n",
        "    \"Questioning_the_Reputation (რეპუტაციის ეჭვქვეშ დაყენება - მორალურ იმიჯზე დარტყმა)\",\n",
        "    \"Obfuscation-Vagueness-Confusion (ბუნდოვანება - მიზანმიმართული,დამაბნეველი ორაზროვნება)\",\n",
        "    \"Flag_Waving (პოპულისტური პატრიოტიზმი - მანიპულაცია ეროვნული პათოსით)\",\n",
        "    \"Red_Herring (ყურადღების გადატანა - არამთავარი თემის შემოტყუება)\",\n",
        "    \"Appeal_to_Hypocrisy (თვალთმაქცობის დაბრალება - ხაზგასმა ორმაგ სტანდარტზე)\",\n",
        "    \"Consequential_Oversimplification (გამარტივებული მიზეზშედეგობრიობა - მანიპულირებული მოვლენათა ჯაჭვი)\",\n",
        "    \"Causal_Oversimplification (მიზეზთა გამარტივება - მრავალფაქტორული პრობლემის გამარტივება)\",\n",
        "    \"Repetition (განმეორებითი რიტორიკა - დაჟინებული ფრაზის ბრუნვა)\",\n",
        "    \"False_Dilemma-No_Choice (ცრუ დილემა - არჩევანის არარსებობის ილუზიის შექმნა)\",\n",
        "    \"Conversation_Killer (დისკუსიის დამხშობი - ნიუანსური დიალოგის ჩახშობა)\",\n",
        "    \"Appeal_to_Fear-Prejudice (შიშით/წინასწარგანწყობით აპელირება - საფთხის გაზვიადებით ზემოქმედება)\",\n",
        "    \"Appeal_to_Values (ღირებულებებით აპელირება - კეთილშობილურ ფასეულობებზე პარაზიტირება)\",\n",
        "    \"Appeal_to_Authority (ავტორიტეტით აპელირება - )\",\n",
        "    \"Straw_Man (ცრუ კონტრარგუმენტი - რეალური თემის გვერდის ავლა)\"\n",
        "\n",
        "]\n",
        "\n",
        "# === Prompt builder (no JSON; zero-shot by default; optional few-shot) ===\n",
        "def build_prompt(text: str) -> str:\n",
        "    intro = (\n",
        "        \"ქვემოთ მოცემული ტექსტისთვის მიუთითე რომელი პროპაგანდის ტექნიკებია გამოყენებული.\\n\"\n",
        "        \"შეგიძლია უპასუხო ინგლისური ლეიბლებით ან ქვემოთ მოცემული ქართული აღწერებით.\\n\"\n",
        "        \"დაასახელე მხოლოდ შესაბამისი ტექნიკების სახელები, მძიმით გამოყოფილი. \"\n",
        "        \"თუ არცერთი არ არის, შეგიძლია დაწერო: None.\\n\\n\"\n",
        "        \"დასაშვები ტექნიკები:\\n- \" + \"\\n- \".join(BILINGUAL) + \"\\n\\n\"\n",
        "    )\n",
        "    few = \"\"\n",
        "    if USE_FEW_SHOT and FEW_SHOTS:\n",
        "        for ex in FEW_SHOTS:\n",
        "            labs = \", \".join(ex[\"labels_en\"])\n",
        "            few += f\"მაგალითი:\\nტექსტი: {ex['text']}\\nტექნიკები: {labs}\\n\\n\"\n",
        "    return (\n",
        "        intro + few +\n",
        "        \"ტექსტი:\\n<<<\" + text.strip() + \">>>\\n\\n\"\n",
        "        \"ტექნიკები: \"\n",
        "    )\n",
        "\n",
        "# === Parsers ===\n",
        "def gold_to_list(s: str) -> List[str]:\n",
        "    s = (s or \"\").strip()\n",
        "    if not s: return []\n",
        "    if s.startswith(\"[\"):\n",
        "        try:\n",
        "            arr = json.loads(s)\n",
        "            return [x for x in arr if x in ALLOWED_LABELS_EN]\n",
        "        except Exception:\n",
        "            pass\n",
        "    parts = re.split(r\"[,\\|;]\\s*\", s)\n",
        "    return [p for p in parts if p in ALLOWED_LABELS_EN]\n",
        "\n",
        "def parse_prediction(raw: str) -> List[str]:\n",
        "    \"\"\"\n",
        "    Accept either EN labels directly or KA forms mapped to EN.\n",
        "    We look only at the first line to avoid rambling.\n",
        "    \"\"\"\n",
        "    line = raw.strip().splitlines()[0] if raw.strip() else \"\"\n",
        "    if \"ტექნიკები\" in line.lower():\n",
        "        line = line.split(\":\", 1)[-1].strip()\n",
        "    # split candidates\n",
        "    parts = [p.strip() for p in re.split(r\"[,\\|;]+\", line) if p.strip()]\n",
        "    out = []\n",
        "    for p in parts:\n",
        "        if p in ALLOWED_LABELS_EN:\n",
        "            out.append(p)\n",
        "            continue\n",
        "        # exact KA match\n",
        "        if p in GEO2EN:\n",
        "            out.append(GEO2EN[p])\n",
        "            continue\n",
        "        # fuzzy KA contains\n",
        "        matched = False\n",
        "        for ka, en in GEO2EN.items():\n",
        "            if ka in p:\n",
        "                out.append(en); matched = True; break\n",
        "        if matched: continue\n",
        "        # tolerate accidental spaces/typos around EN labels\n",
        "        for en in ALLOWED_LABELS_EN:\n",
        "            if en.replace(\"_\",\" \").lower() == p.replace(\"_\",\" \").lower():\n",
        "                out.append(en); break\n",
        "    # dedupe, keep order, filter\n",
        "    seen = set()\n",
        "    clean = [x for x in out if (x in ALLOWED_LABELS_EN and (x not in seen and not seen.add(x)))]\n",
        "    if len(clean) == 1 and clean[0].lower() == \"none\":\n",
        "        return []\n",
        "    return clean\n",
        "\n",
        "def binarize(batch: List[List[str]]):\n",
        "    idx = {lab:i for i,lab in enumerate(ALLOWED_LABELS_EN)}\n",
        "    Y = np.zeros((len(batch), len(ALLOWED_LABELS_EN)), dtype=int)\n",
        "    for r, labs in enumerate(batch):\n",
        "        for lab in labs:\n",
        "            if lab in idx:\n",
        "                Y[r, idx[lab]] = 1\n",
        "    return Y\n",
        "\n",
        "# === Load data ===\n",
        "rows = []\n",
        "with open(CSV_PATH, newline=\"\", encoding=\"utf-8\") as f:\n",
        "    for r in csv.DictReader(f):\n",
        "        rows.append({\"text\": r[\"text\"], \"gold\": gold_to_list(r[\"labels\"])})\n",
        "print(f\"Loaded {len(rows)} rows from {CSV_PATH}\")\n",
        "assert rows, \"CSV is empty or path is wrong.\"\n",
        "\n",
        "# === Load model ===\n",
        "try:\n",
        "    tok = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "    model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, torch_dtype=\"auto\", device_map=\"auto\")\n",
        "except Exception as e:\n",
        "    print(\"Falling back to CPU due to loading error:\", e)\n",
        "    tok = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "    model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, device_map=\"cpu\")\n",
        "\n",
        "cfg = GenerationConfig(max_new_tokens=64, temperature=0.7, top_p=0.95, do_sample=True)\n",
        "\n",
        "# === Inference ===\n",
        "preds, golds = [], []\n",
        "for i, r in enumerate(rows, 1):\n",
        "    prompt = build_prompt(r[\"text\"])\n",
        "    inputs = tok(prompt, return_tensors=\"pt\").to(model.device)\n",
        "    with torch.no_grad():\n",
        "        out = model.generate(**inputs, generation_config=cfg)\n",
        "    raw = tok.decode(out[0][inputs[\"input_ids\"].shape[1]:], skip_special_tokens=True)\n",
        "    plabels = parse_prediction(raw)\n",
        "    preds.append(plabels); golds.append(r[\"gold\"])\n",
        "\n",
        "    if i <= 5:\n",
        "        print(f\"\\n--- EXAMPLE {i} ---\")\n",
        "        print(\"RAW:\", raw[:400].replace(\"\\n\",\" \"))\n",
        "        print(\"PRED:\", plabels)\n",
        "        print(\"GOLD:\", r[\"gold\"])\n",
        "\n",
        "# === Metrics ===\n",
        "Y_true, Y_pred = binarize(golds), binarize(preds)\n",
        "micro = precision_recall_fscore_support(Y_true, Y_pred, average=\"micro\", zero_division=0)\n",
        "macro = precision_recall_fscore_support(Y_true, Y_pred, average=\"macro\", zero_division=0)\n",
        "\n",
        "print(\"\\n=== ZERO-SHOT (no JSON) RESULTS ===\")\n",
        "print(f\"Micro P/R/F1: {micro[0]:.3f}/{micro[1]:.3f}/{micro[2]:.3f}\")\n",
        "print(f\"Macro P/R/F1: {macro[0]:.3f}/{macro[1]:.3f}/{macro[2]:.3f}\")\n",
        "\n",
        "# Per-label (optional)\n",
        "per = precision_recall_fscore_support(Y_true, Y_pred, average=None, zero_division=0)\n",
        "print(\"\\nPer-label F1:\")\n",
        "for lab, f1 in zip(ALLOWED_LABELS_EN, per[2]):\n",
        "    print(f\"{lab}: {f1:.3f}\")\n"
      ],
      "metadata": {
        "id": "ESUX9F8TzbR9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}